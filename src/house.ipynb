{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from doodleLoaderSimple import DoodleDatasetSimple\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation for the house image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cognitive computing focuses on mimicking human behaviour and reasoning to solve complex problems\n",
    "2. It simulates human thought process to find solutions to complex problems \n",
    "3. They simple supplements information for human to take decisions\n",
    "4. it is most likey to be used in sectors like customer service, healthcare industry etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. AI augments human thinking to solve complex problems. It focuses on providing accurate results\n",
    "2. AI find patterns to learn or reveal hidden information to find solutions.\n",
    "3. AI is responsible for making decisions on their own minimizing the role of humans.\n",
    "4. It is mostly used in finance, security, healthcare, retail, manufacturing etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ksi SZA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0) (1, 1) (2, 2) (3, 0) (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Number to class labels mapping\n",
    "class_dict = {\n",
    "    0: 'stress',\n",
    "    1: 'introvert',\n",
    "    2: 'extrovert'\n",
    "}\n",
    "\n",
    "# Loading the data from the .csv file\n",
    "# First row is a header\n",
    "data = np.genfromtxt('D:\\COLLEGE_STUDIES\\SEM-6\\ML_NLP_project\\data\\houseData.csv', dtype=int, delimiter=',', names=True)\n",
    "\n",
    "print(data[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translation_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Call the function to visualize the dataset distribution\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m plot_class_distribution(\u001b[43mtranslation_dict\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translation_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# # Visualization: Plot the distribution of classes\n",
    "# def plot_class_distribution(translation_dict):\n",
    "#     \"\"\"\n",
    "#     Plots the distribution of class labels in the dataset.\n",
    "    \n",
    "#     :param translation_dict: Dictionary mapping image filenames to class labels.\n",
    "#     \"\"\"\n",
    "#     class_counts = np.bincount(list(translation_dict.values()))  # Count occurrences of each class\n",
    "#     class_labels = [class_dict[i] for i in range(len(class_counts))]  # Get class names\n",
    "    \n",
    "#     plt.figure(figsize=(4, 3))\n",
    "#     plt.bar(class_labels, class_counts, color=['red', 'blue', 'green'])\n",
    "#     plt.xlabel(\"Class Labels\")\n",
    "#     plt.ylabel(\"Number of Images\")\n",
    "#     plt.title(\"Class Distribution in Dataset\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Call the function to visualize the dataset distribution\n",
    "# plot_class_distribution(translation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(dictClass, arr):\n",
    "    \"\"\"\n",
    "    Redundant method that counts the occurrences of each class in the dataset\n",
    "    Can be used to create weights if the class distribution is unbalanced\n",
    "    :param dictClass: Dictionary that maps number to class labels\n",
    "    :param arr: The array that contains the data\n",
    "    :return: The number of occurrences for each class in the given array\n",
    "    \"\"\"\n",
    "    unique, count = numpy.unique(arr, return_counts=True)\n",
    "    print(dict(zip(dictClass.values(), count)))\n",
    "    count = 1 / count\n",
    "    count = count / sum(count)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the image IDs to the ID values in the .csv file.\n",
    "translation_dict = dict( zip([f'{id}.png' for id in data['id']], data['class']))\n",
    "\n",
    "# Prepare each image to be passed as a Tensor product to the model.\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Prepare the data by matching it to its label and transforming it to a Tensor product.\n",
    "housedata = DoodleDatasetSimple(r'D:\\\\COLLEGE_STUDIES\\\\SEM-6\\\\ML_NLP_project\\\\images\\\\house\\\\', data_transforms, translation_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% of the data for training.\n",
    "train_len = int(housedata.__len__() * 0.8)\n",
    "# 20% of the data for validation.\n",
    "test_len = int(housedata.__len__() * 0.2 + 1)\n",
    "# Split the data at a random point.\n",
    "train_set, val_set = torch.utils.data.random_split(housedata, [train_len, test_len])\n",
    "# Shuffle and load the labeled images in batches of 4 for training.\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True, num_workers=0, drop_last=True)\n",
    "# Load the labeled images in batches of 4 for validation after training the model.\n",
    "test_loader = DataLoader(val_set, batch_size=4, shuffle=False, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Class that contains the layers for the model.\n",
    "    Starting model ResNet-34, replace last layer with a Linear layer that outputs\n",
    "    a single number, the label of the image.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        self.model_wo_fc = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "\n",
    "        self.imageClass = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=512, out_features=n_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_wo_fc(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return {\n",
    "            'class': self.imageClass(x)\n",
    "        }\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Set the device to use as the GPU if there is compatible hardware\n",
    "# Otherwise run the model on the cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultilabelClassifier(3).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, pictures):\n",
    "    \"\"\"\n",
    "    Method used by the model as the criterion for training.\n",
    "    Cross entropy loss used as the loss function\n",
    "    :param outputs: Predicted labels by the model\n",
    "    :param pictures: Actual labeled images from the dataset\n",
    "    :return: The sum of the cross entropy loss function.\n",
    "    \"\"\"\n",
    "    losses = 0\n",
    "\n",
    "    for i, key in enumerate(outputs):\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        labelsTensor = pictures['class'].clone().detach()\n",
    "        losses += loss_func(outputs[key], labelsTensor.long().to(device))\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, device, lr_rate, epochs, train_loader):\n",
    "    \"\"\"\n",
    "    Method used by the model for training\n",
    "    :param model: The model to train\n",
    "    :param device: Which device to use for computation, GPU or CPU\n",
    "    :param lr_rate: The learning rate used by the optimizing function\n",
    "    :param epochs: How many epochs to train the model for\n",
    "    :param train_loader: The loader that provides the labeled images in batches\n",
    "    :return: An array containing the losses after each epoch\n",
    "    \"\"\"\n",
    "    num_epochs = epochs\n",
    "    losses = []\n",
    "    checkpoint_losses = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "    n_total_steps = len(train_loader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, pictures in enumerate(train_loader):\n",
    "            images = pictures['image'].to(device)\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output, pictures)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % (int(n_total_steps / 1)) == 0:\n",
    "                checkpoint_loss = torch.tensor(losses).mean().item()\n",
    "                checkpoint_losses.append(checkpoint_loss)\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{n_total_steps}], Loss: {checkpoint_loss:.4f}')\n",
    "\n",
    "    # Snippet used to save the models for inferring during runtime.\n",
    "    model_save_path = r'D:\\COLLEGE_STUDIES\\SEM-6\\ML_NLP_project\\model\\house\\house_model_12.tar'\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': checkpoint_losses,\n",
    "    }, model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "    return checkpoint_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Call the method to train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m checkpoint_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 15\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, device, lr_rate, epochs, train_loader)\u001b[0m\n\u001b[0;32m     12\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m checkpoint_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m n_total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:78\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     67\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     68\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused,\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:371\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    368\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_compile.py:27\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:53\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     _disable_current_modes,\n\u001b[0;32m     49\u001b[0m     is_in_torch_dispatch_mode,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback, format_traceback_short\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     56\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[0;32m     57\u001b[0m     Instruction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     transform_code_object,\n\u001b[0;32m     61\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     BuiltinVariable,\n\u001b[0;32m     48\u001b[0m     FunctionalCallVariable,\n\u001b[0;32m     49\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[0;32m     50\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     51\u001b[0m     PolyfilledFunctionVariable,\n\u001b[0;32m     52\u001b[0m     SkipFunctionVariable,\n\u001b[0;32m     53\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[0;32m     54\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     55\u001b[0m     UserMethodVariable,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     59\u001b[0m np: Optional[types\u001b[38;5;241m.\u001b[39mModuleType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:104\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SDPAParamsVariable\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     97\u001b[0m     FakeItemVariable,\n\u001b[0;32m     98\u001b[0m     NumpyNdarrayVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     UntypedStorageVariable,\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchCtxManagerClassVariable, TorchInGraphFunctionVariable\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_defined\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    106\u001b[0m     MutableMappingVariable,\n\u001b[0;32m    107\u001b[0m     RemovableHandleVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m     WeakRefVariable,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    114\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionContextVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWithExitFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    179\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\variables\\torch.py:142\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Convert to dict for O(1) access times\u001b[39;00m\n\u001b[0;32m    133\u001b[0m constant_fold_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(constant_fold_functions)\n\u001b[0;32m    136\u001b[0m tracing_state_functions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    137\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    138\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    139\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    140\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39m_symbolic_trace\u001b[38;5;241m.\u001b[39mis_fx_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mis_in_onnx_export: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m--> 142\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexternal_utils\u001b[49m\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    144\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    145\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_dynamo_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    146\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mactivation\u001b[38;5;241m.\u001b[39m_is_make_fx_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m }\n\u001b[0;32m    149\u001b[0m bin_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBaseTorchVariable\u001b[39;00m(VariableTracker):\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Call the method to train the model\n",
    "checkpoint_losses = training(model, device, 0.0001, 12, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def validation(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Validates the model after training.\n",
    "\n",
    "    :param model: The trained model.\n",
    "    :param dataloader: Dataloader providing labeled images in batches.\n",
    "    :param device: Device (CPU or GPU) for computation.\n",
    "    :return: Model accuracy in percentage.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pictures in dataloader:\n",
    "            images = pictures['image'].to(device)\n",
    "            labels = pictures['class'].to(device)\n",
    "\n",
    "            outputs = model(images)['class']  # Extract class predictions\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class indices\n",
    "\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            n_samples += labels.size(0)\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples if n_samples > 0 else 0.0  # Avoid division by zero\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 98.15%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Ensure correct device\n",
    "model.to(device)  # Move model to device\n",
    "\n",
    "# Call the validation function\n",
    "accuracy = validation(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
